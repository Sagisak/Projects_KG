{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9adbb11d-18a7-430c-a4d1-dc382d3fb9dc",
   "metadata": {},
   "source": [
    "# Random Forest Model for classifying Gender by Indonesian names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a54f2d-0bd7-420f-941a-576a6a8a0557",
   "metadata": {},
   "source": [
    "## Import necessary files needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ebb7fd2-1e44-486f-af66-431dc86fde42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from random_forest_cart import RandomForestCART\n",
    "from random_forest_cart import CARTTree\n",
    "# Load the trained model and preprocessing tools\n",
    "rf = joblib.load(\"random_forest_cart.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "selector = joblib.load(\"selector.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0987b60f-9cf8-4d6a-baac-431c36c9d648",
   "metadata": {},
   "source": [
    "## Two option for model that needed to be run first:\n",
    "1. Retrieve and Inserting Data from SQL server\n",
    "2. Retrieve the data from an CSV and save it into a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e729e3ab-2d43-45f2-ab6b-592a24e450bb",
   "metadata": {},
   "source": [
    "### OPTION 1: Retrieve and Inserting data from SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20864d-35f5-4862-8cc6-03205b352f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to fetch and preprocess data\n",
    "def preprocessing_dataset():\n",
    "    print(\"Connecting to SQL Server...\")\n",
    "    try:\n",
    "        # Define connection string (replace with your actual SQL Server details)\n",
    "        conn = pyodbc.connect(\n",
    "            \"DRIVER={SQL Server};\"\n",
    "            \"SERVER=10.12.30.240;\"\n",
    "            \"DATABASE=GORPDWHBI;\"  # Replace with your database name\n",
    "            \"UID=viewer;\"\n",
    "            \"PWD=viewer1;\"\n",
    "        )\n",
    "        print(\"Successfully connected to SQL Server!\")\n",
    "\n",
    "        # Query to fetch the required columns\n",
    "        query = \"\"\"\n",
    "        WITH RankedCustomers AS (\n",
    "            SELECT \n",
    "                MyValueId, \n",
    "                CustomerName, \n",
    "                Gender,\n",
    "                ROW_NUMBER() OVER (PARTITION BY CustomerName ORDER BY MyValueId ASC) AS row_num\n",
    "            FROM dbo.DimCustomer\n",
    "            WHERE Gender NOT IN ('F', 'M')\n",
    "              AND MyValueId IS NOT NULL \n",
    "              AND CustomerName IS NOT NULL\n",
    "              AND LTRIM(RTRIM(MyValueId)) <> ''  \n",
    "              AND LTRIM(RTRIM(CustomerName)) <> ''  \n",
    "        )\n",
    "        SELECT MyValueId, CustomerName, Gender \n",
    "        FROM RankedCustomers\n",
    "        WHERE row_num = 1;\n",
    "         \"\"\"\n",
    "        print(\"Processing query...\")\n",
    "\n",
    "        # Read the data from SQL Server\n",
    "        GenderData = pd.read_sql(query, conn)\n",
    "        print(\"Successfully fetched data from SQL Server!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect or fetch data: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        # Close connection\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n",
    "\n",
    "    # Drop null values in 'CustomerName'\n",
    "    print(\"Cleaning data...\")\n",
    "    GenderData = GenderData.dropna(subset=['CustomerName'])\n",
    "    print(\"Data successfully cleaned!\")\n",
    "\n",
    "    # Function to split names\n",
    "    def split_name(name):\n",
    "        name = name.lower()\n",
    "        parts = name.split()\n",
    "        \n",
    "        first_name = second_name = third_name = fourth_name = last_name = ' '\n",
    "        \n",
    "        if len(parts) >= 1:\n",
    "            first_name = parts[0]\n",
    "        if len(parts) >= 2:\n",
    "            second_name = parts[1]\n",
    "        if len(parts) >= 3:\n",
    "            third_name = parts[2]\n",
    "        if len(parts) >= 4:\n",
    "            fourth_name = parts[3]\n",
    "        if len(parts) >= 5:\n",
    "            last_name = ' '.join(parts[4:])\n",
    "        \n",
    "        return pd.Series([first_name, second_name, third_name, fourth_name, last_name])\n",
    "    \n",
    "    # Apply function to DataFrame\n",
    "    print(\"Splitting customer names into individual parts...\")\n",
    "    GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']] = GenderData['CustomerName'].apply(split_name)\n",
    "    print(\"Name splitting completed!\")\n",
    "\n",
    "    # Drop original 'CustomerName' and 'Gender' columns\n",
    "    columns_to_drop = ['CustomerName', 'Gender']\n",
    "    GenderData = GenderData.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    print(\"Preprocessing completed successfully!\")\n",
    "\n",
    "    return GenderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80e723-70e7-4a39-a200-4cc2f95691be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def run_prediction():\n",
    "    print(\"Starting the prediction process...\")\n",
    "\n",
    "    # Log execution time\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Script executed at: {timestamp}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch and preprocess data\n",
    "        print(\"Fetching and preprocessing dataset from SQL Server...\")\n",
    "        GenderData = preprocessing_dataset()\n",
    "        if GenderData is None or GenderData.empty:\n",
    "            print(\"No data retrieved. Exiting process.\")\n",
    "            return\n",
    "        print(\"Data fetched and preprocessed successfully!\")\n",
    "\n",
    "        def get_bigrams(name):\n",
    "            return ' '.join(name[i:i+2] for i in range(len(name)-1)) if isinstance(name, str) else \"\"\n",
    "\n",
    "\n",
    "        # Join all name columns into a single column\n",
    "        X_new = GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']].astype(str)\n",
    "        GenderData[\"CustomerName\"] = X_new.apply(lambda row: ' '.join(row).strip(), axis=1)\n",
    "\n",
    "        # Extract bigrams\n",
    "        print(\"Extracting bigrams...\")\n",
    "        X_new = X_new.map(get_bigrams)\n",
    "        X_new[\"FullName\"] = X_new.apply(lambda row: ' '.join(row), axis=1)\n",
    "        print(\"Bigrams extracted!\")\n",
    "\n",
    "        # Apply HashingVectorizer\n",
    "        print(\"Applying feature transformation...\")\n",
    "        X_new_hashed = vectorizer.transform(X_new[\"FullName\"])  \n",
    "        X_new_df = pd.DataFrame(X_new_hashed.toarray())\n",
    "        print(\"Feature transformation completed!\")\n",
    "\n",
    "        # Remove low-variance features\n",
    "        print(\"Removing low-variance features...\")\n",
    "        X_new_df = pd.DataFrame(selector.transform(X_new_df))\n",
    "        print(\"Low-variance features removed!\")\n",
    "\n",
    "        # Scale features\n",
    "        print(\"Scaling features...\")\n",
    "        X_new_scaled = scaler.transform(X_new_df)\n",
    "        print(\"Feature scaling completed!\")\n",
    "\n",
    "        # Predict using the trained model\n",
    "        print(\"Model is predicting genders...\")\n",
    "        y_pred_new = rf.predict(X_new_scaled)\n",
    "        print(\"Prediction completed!\")\n",
    "\n",
    "        # Map predictions back to 'M' and 'F'\n",
    "        print(\"Mapping predictions to labels...\")\n",
    "        GenderData[\"Predicted_Gender\"] = np.where(y_pred_new == 0, 'M', 'F')\n",
    "        GenderData = GenderData[[\"CustomerName\", \"Predicted_Gender\"]]\n",
    "        print(\"Mapping completed!\")\n",
    "\n",
    "        # Show preview of mapped data\n",
    "        print(\"Preview of predicted data:\")\n",
    "        print(GenderData.head())  # Show first 5 rows\n",
    "        conn = pyodbc.connect(\n",
    "            \"DRIVER={SQL Server};\"\n",
    "            \"SERVER=10.12.30.240;\"\n",
    "            \"DATABASE=GORPDWHBI;\"\n",
    "            \"UID=viewer;\"\n",
    "            \"PWD=viewer1;\"\n",
    "        )\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Ensure no NaN values\n",
    "        GenderData = GenderData.dropna(subset=[\"CustomerName\", \"Predicted_Gender\"])\n",
    "        \n",
    "        # Loop through DataFrame rows and insert into SQL Server\n",
    "        print(\"Inserting predicted data into SQL Server...\")\n",
    "        for index, row in GenderData.iterrows():\n",
    "            cursor.execute(\"\"\"\n",
    "                MERGE INTO dbo.MemberGenderPrediction AS target\n",
    "                USING (SELECT ? AS CustomerName, ? AS GenderPrediction) AS source\n",
    "                ON target.CustomerName = source.CustomerName\n",
    "                WHEN NOT MATCHED THEN\n",
    "                    INSERT (CustomerName, GenderPrediction) VALUES (source.CustomerName, source.GenderPrediction);\n",
    "            \"\"\", (row[\"CustomerName\"], row[\"Predicted_Gender\"]))\n",
    "\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"Data inserted successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    print(\"Prediction process completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15e562b-e845-492c-867d-6e6a8c465d5b",
   "metadata": {},
   "source": [
    "### OPTION 2: Retrieve the data from an CSV and save it into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ddc2b7d-3602-4392-99ad-4c5fbb72af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to fetch and preprocess data\n",
    "def preprocessing_dataset():\n",
    "    print(\"Taking data from dataset...\")\n",
    "    try:\n",
    "        GenderData = pd.read_csv(\"DatasetGenderNeededClarify.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        print(\"Data get!\")\n",
    "\n",
    "    # Drop null values in 'CustomerName'\n",
    "    print(\"Cleaning data...\")\n",
    "    GenderData = GenderData.dropna(subset=['CustomerName'])\n",
    "    print(\"Data successfully cleaned!\")\n",
    "\n",
    "    # Function to split names\n",
    "    def split_name(name):\n",
    "        name = name.lower()\n",
    "        parts = name.split()\n",
    "        \n",
    "        first_name = second_name = third_name = fourth_name = last_name = ' '\n",
    "        \n",
    "        if len(parts) >= 1:\n",
    "            first_name = parts[0]\n",
    "        if len(parts) >= 2:\n",
    "            second_name = parts[1]\n",
    "        if len(parts) >= 3:\n",
    "            third_name = parts[2]\n",
    "        if len(parts) >= 4:\n",
    "            fourth_name = parts[3]\n",
    "        if len(parts) >= 5:\n",
    "            last_name = ' '.join(parts[4:])\n",
    "        \n",
    "        return pd.Series([first_name, second_name, third_name, fourth_name, last_name])\n",
    "    \n",
    "    # Apply function to DataFrame\n",
    "    print(\"Splitting customer names into individual parts...\")\n",
    "    GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']] = GenderData['CustomerName'].apply(split_name)\n",
    "    print(\"Name splitting completed!\")\n",
    "\n",
    "    # Drop original 'CustomerName' and 'Gender' columns\n",
    "    columns_to_drop = ['CustomerName', 'Gender']\n",
    "    GenderData = GenderData.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    print(\"Preprocessing completed successfully!\")\n",
    "\n",
    "    return GenderData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15b6f3a-36c4-46ad-8d87-9f3f1be04ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def run_prediction():\n",
    "    print(\"Starting the prediction process...\")\n",
    "\n",
    "    # Log execution time\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Script executed at: {timestamp}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch and preprocess data\n",
    "        print(\"Fetching and preprocessing dataset from csv...\")\n",
    "        GenderData = preprocessing_dataset()\n",
    "        if GenderData is None or GenderData.empty:\n",
    "            print(\"No data retrieved. Exiting process.\")\n",
    "            return\n",
    "        print(\"Data fetched and preprocessed successfully!\")\n",
    "\n",
    "        def get_bigrams(name):\n",
    "            return ' '.join(name[i:i+2] for i in range(len(name)-1)) if isinstance(name, str) else \"\"\n",
    "\n",
    "        # Join all name columns into a single column\n",
    "        X_new = GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']].astype(str)\n",
    "        GenderData[\"CustomerName\"] = X_new.apply(lambda row: ' '.join(row).strip(), axis=1)\n",
    "\n",
    "        # Extract bigrams\n",
    "        print(\"Extracting bigrams...\")\n",
    "        X_new = X_new.map(get_bigrams)\n",
    "        X_new[\"FullName\"] = X_new.apply(lambda row: ' '.join(row), axis=1)\n",
    "        print(\"Bigrams extracted!\")\n",
    "\n",
    "        # Apply HashingVectorizer\n",
    "        print(\"Applying feature transformation...\")\n",
    "        X_new_hashed = vectorizer.transform(X_new[\"FullName\"])  \n",
    "        X_new_df = pd.DataFrame(X_new_hashed.toarray())\n",
    "        print(\"Feature transformation completed!\")\n",
    "\n",
    "        # Remove low-variance features\n",
    "        print(\"Removing low-variance features...\")\n",
    "        X_new_df = pd.DataFrame(selector.transform(X_new_df))\n",
    "        print(\"Low-variance features removed!\")\n",
    "\n",
    "        # Scale features\n",
    "        print(\"Scaling features...\")\n",
    "        X_new_scaled = scaler.transform(X_new_df)\n",
    "        print(\"Feature scaling completed!\")\n",
    "\n",
    "        # Predict using the trained model\n",
    "        print(\"Model is predicting genders...\")\n",
    "        y_pred_new = rf.predict(X_new_scaled)\n",
    "        print(\"Prediction completed!\")\n",
    "\n",
    "        # Map predictions back to 'M' and 'F'\n",
    "        print(\"Mapping predictions to labels...\")\n",
    "        GenderData[\"Predicted_Gender\"] = np.where(y_pred_new == 0, 'M', 'F')\n",
    "        GenderData = GenderData[[\"MyValueId\", \"CustomerName\", \"Predicted_Gender\"]]\n",
    "        print(\"Mapping completed!\")\n",
    "\n",
    "        # Show preview of mapped data\n",
    "        print(\"Preview of predicted data:\")\n",
    "        print(GenderData.head(10))  # Show first 10 rows\n",
    "        \n",
    "        # Save output\n",
    "        output_filename = f\"GenderData_Predicted_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        GenderData.head(100).to_csv(output_filename, index=False)\n",
    "        print(f\"Predicted data (first 100 rows) saved successfully as {output_filename}!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    print(\"Prediction process completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be362b3c-54c2-42e0-ad00-a4735e0f0cdb",
   "metadata": {},
   "source": [
    "## Below code is too start the program!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c174b3d3-11f3-4a9a-95cd-c798726184a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the prediction process...\n",
      "Script executed at: 2025-02-10 11:56:32\n",
      "Fetching and preprocessing dataset from csv...\n",
      "Taking data from dataset...\n",
      "Data get!\n",
      "Cleaning data...\n",
      "Data successfully cleaned!\n",
      "Splitting customer names into individual parts...\n",
      "Name splitting completed!\n",
      "Preprocessing completed successfully!\n",
      "Data fetched and preprocessed successfully!\n",
      "Extracting bigrams...\n",
      "Bigrams extracted!\n",
      "Applying feature transformation...\n",
      "Feature transformation completed!\n",
      "Removing low-variance features...\n",
      "Low-variance features removed!\n",
      "Scaling features...\n",
      "Feature scaling completed!\n",
      "Model is predicting genders...\n",
      "Prediction completed!\n",
      "Mapping predictions to labels...\n",
      "Mapping completed!\n",
      "Preview of predicted data:\n",
      "  MyValueId                CustomerName Predicted_Gender\n",
      "0    VJDLSC               aprilia silmi                F\n",
      "1    VT4RFF          sasta citra fauzia                F\n",
      "2    VHVSRM                 ð’…ð’†ð’…ð’† sopiah                F\n",
      "3    VEUOAU               ade mai putra                M\n",
      "4    VL6UJM          lisah maya susanti                F\n",
      "5    VO3ZT8                samsul bahri                M\n",
      "6    V66AJO       sheren noviana kusuma                M\n",
      "7    VSAVMB                  zulfikar .                F\n",
      "8    VZLFKP                     ?rahmat                F\n",
      "9    V1C3EI  01fgusti ayu tiara vianita                F\n",
      "Predicted data (first 100 rows) saved successfully as GenderData_Predicted_20250210_121054.csv!\n",
      "Prediction process completed!\n",
      "Testing Time: 864.3541 seconds\n",
      "Sleeping for 15 minutes...\n",
      "Starting the prediction process...\n",
      "Script executed at: 2025-02-10 12:25:57\n",
      "Fetching and preprocessing dataset from csv...\n",
      "Taking data from dataset...\n",
      "Data get!\n",
      "Cleaning data...\n",
      "Data successfully cleaned!\n",
      "Splitting customer names into individual parts...\n",
      "Name splitting completed!\n",
      "Preprocessing completed successfully!\n",
      "Data fetched and preprocessed successfully!\n",
      "Extracting bigrams...\n",
      "Bigrams extracted!\n",
      "Applying feature transformation...\n",
      "Feature transformation completed!\n",
      "Removing low-variance features...\n",
      "Low-variance features removed!\n",
      "Scaling features...\n",
      "Feature scaling completed!\n",
      "Model is predicting genders...\n",
      "Prediction completed!\n",
      "Mapping predictions to labels...\n",
      "Mapping completed!\n",
      "Preview of predicted data:\n",
      "  MyValueId                CustomerName Predicted_Gender\n",
      "0    VJDLSC               aprilia silmi                F\n",
      "1    VT4RFF          sasta citra fauzia                F\n",
      "2    VHVSRM                 ð’…ð’†ð’…ð’† sopiah                F\n",
      "3    VEUOAU               ade mai putra                M\n",
      "4    VL6UJM          lisah maya susanti                F\n",
      "5    VO3ZT8                samsul bahri                M\n",
      "6    V66AJO       sheren noviana kusuma                M\n",
      "7    VSAVMB                  zulfikar .                F\n",
      "8    VZLFKP                     ?rahmat                F\n",
      "9    V1C3EI  01fgusti ayu tiara vianita                F\n",
      "Predicted data (first 100 rows) saved successfully as GenderData_Predicted_20250210_123930.csv!\n",
      "Prediction process completed!\n",
      "Testing Time: 815.9423 seconds\n",
      "Sleeping for 15 minutes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Sleep for 15 hour (900 seconds)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSleeping for 15 minutes...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m900\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    start_prediction_time = time.time()\n",
    "    run_prediction()\n",
    "    end_prediction_time = time.time()\n",
    "    print(f\"Testing Time: {end_prediction_time - start_prediction_time:.4f} seconds\")\n",
    "    \n",
    "    # Sleep for 15 hour (900 seconds)\n",
    "    \n",
    "    print(\"Sleeping for 15 minutes...\")\n",
    "    time.sleep(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0cc21-6295-4579-a252-d76f6dd83ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
