





import joblib
from random_forest_cart import RandomForestCART
from random_forest_cart import CARTTree
# Load the trained model and preprocessing tools
rf = joblib.load("random_forest_cart.pkl")
vectorizer = joblib.load("vectorizer.pkl")
selector = joblib.load("selector.pkl")
scaler = joblib.load("scaler.pkl")








import pyodbc
import pandas as pd

# Define the function to fetch and preprocess data
def preprocessing_dataset():
    print("Connecting to SQL Server...")
    try:
        # Define connection string (replace with your actual SQL Server details)
        conn = pyodbc.connect(
            "DRIVER={SQL Server};"
            "SERVER=10.12.30.240;"
            "DATABASE=GORPDWHBI;"  # Replace with your database name
            "UID=viewer;"
            "PWD=viewer1;"
        )
        print("Successfully connected to SQL Server!")

        # Query to fetch the required columns
        query = """
        WITH RankedCustomers AS (
            SELECT 
                MyValueId, 
                CustomerName, 
                Gender,
                ROW_NUMBER() OVER (PARTITION BY CustomerName ORDER BY MyValueId ASC) AS row_num
            FROM dbo.DimCustomer
            WHERE Gender NOT IN ('F', 'M')
              AND MyValueId IS NOT NULL 
              AND CustomerName IS NOT NULL
              AND LTRIM(RTRIM(MyValueId)) <> ''  
              AND LTRIM(RTRIM(CustomerName)) <> ''  
        )
        SELECT MyValueId, CustomerName, Gender 
        FROM RankedCustomers
        WHERE row_num = 1;
         """
        print("Processing query...")

        # Read the data from SQL Server
        GenderData = pd.read_sql(query, conn)
        print("Successfully fetched data from SQL Server!")

    except Exception as e:
        print(f"Failed to connect or fetch data: {e}")
        return None
    finally:
        # Close connection
        conn.close()
        print("Connection closed.")

    # Drop null values in 'CustomerName'
    print("Cleaning data...")
    GenderData = GenderData.dropna(subset=['CustomerName'])
    print("Data successfully cleaned!")

    # Function to split names
    def split_name(name):
        name = name.lower()
        parts = name.split()
        
        first_name = second_name = third_name = fourth_name = last_name = ' '
        
        if len(parts) >= 1:
            first_name = parts[0]
        if len(parts) >= 2:
            second_name = parts[1]
        if len(parts) >= 3:
            third_name = parts[2]
        if len(parts) >= 4:
            fourth_name = parts[3]
        if len(parts) >= 5:
            last_name = ' '.join(parts[4:])
        
        return pd.Series([first_name, second_name, third_name, fourth_name, last_name])
    
    # Apply function to DataFrame
    print("Splitting customer names into individual parts...")
    GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']] = GenderData['CustomerName'].apply(split_name)
    print("Name splitting completed!")

    # Drop original 'CustomerName' and 'Gender' columns
    columns_to_drop = ['CustomerName', 'Gender']
    GenderData = GenderData.drop(columns=columns_to_drop, errors='ignore')
    
    print("Preprocessing completed successfully!")

    return GenderData


import time
import pandas as pd
import numpy as np
from datetime import datetime

def run_prediction():
    start_algorithm_time = time.time()
    print("Starting the algorithm...")

    # Log execution time
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"Script executed at: {timestamp}")

    try:
        # Fetch and preprocess data
        start_prediction_time = time.time()
        print("Starting the prediction process...")
        print("Fetching and preprocessing dataset from SQL Server...")
        GenderData = preprocessing_dataset()
        if GenderData is None or GenderData.empty:
            print("No data retrieved. Exiting process.")
            return
        print("Data fetched and preprocessed successfully!")

        def get_bigrams(name):
            return ' '.join(name[i:i+2] for i in range(len(name)-1)) if isinstance(name, str) else ""


        # Join all name columns into a single column
        X_new = GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']].astype(str)
        GenderData["CustomerName"] = X_new.apply(lambda row: ' '.join(row).strip(), axis=1)

        # Extract bigrams
        print("Extracting bigrams...")
        X_new = X_new.map(get_bigrams)
        X_new["FullName"] = X_new.apply(lambda row: ' '.join(row), axis=1)
        print("Bigrams extracted!")

        # Apply HashingVectorizer
        print("Applying feature transformation...")
        X_new_hashed = vectorizer.transform(X_new["FullName"])  
        X_new_df = pd.DataFrame(X_new_hashed.toarray())
        print("Feature transformation completed!")

        # Remove low-variance features
        print("Removing low-variance features...")
        X_new_df = pd.DataFrame(selector.transform(X_new_df))
        print("Low-variance features removed!")

        # Scale features
        print("Scaling features...")
        X_new_scaled = scaler.transform(X_new_df)
        print("Feature scaling completed!")

        # Predict using the trained model
        print("Model is predicting genders...")
        y_pred_new = rf.predict(X_new_scaled)
        print("Prediction completed!")

        # Map predictions back to 'M' and 'F'
        print("Mapping predictions to labels...")
        GenderData["Predicted_Gender"] = np.where(y_pred_new == 0, 'M', 'F')
        GenderData = GenderData[["MyValueId", "CustomerName", "Predicted_Gender"]]
        print("Mapping completed!")

        
        end_prediction_time = time.time()
        elapsed_prediction_time = end_prediction_time - start_prediction_time
        minutes = int(elapsed_prediction_time // 60)  # Get whole minutes
        seconds = int(elapsed_prediction_time % 60)   # Get remaining seconds

        print(f"Model estimated time completed: {minutes} minutes and {seconds} seconds")
        
        print("Prediction process completed!")
        

        # Show preview of mapped data
        print("Preview of predicted data:")
        print(GenderData.head(10))  # Show first 10 rows
        conn = pyodbc.connect(
            "DRIVER={SQL Server};"
            "SERVER=10.12.30.240;"
            "DATABASE=GORPDWHBI;"
            "UID=viewer;"
            "PWD=viewer1;"
        )
        
        cursor = conn.cursor()
        
        
       # Loop through DataFrame rows and insert into SQL Server
        # Loop through DataFrame rows and insert into SQL Server
        print("Inserting predicted data into SQL Server...")

        if GenderData.empty:
            print("GenderData is empty, nothing to insert.")
        else:
            # Initialize counters
            total_inserted = 0
            commit_threshold = 1000  # Commit every 1000 rows
            
            # Get the total number of rows in GenderData
            total_rows = len(GenderData)
            start_time = time.time()
            
            for index, row in GenderData.iterrows():
                try:
                    # Print progress every 1000 rows (or adjust based on preference) and commit it
                    if total_inserted % commit_threshold == 0 and total_inserted > 0:
                        # Commit after 1000 rows
                        conn.commit()
                        print(f"Committed {commit_threshold} rows to the database.")
                        
                        # Calculate and print progress
                        elapsed_time = time.time() - start_time
                        progress_percentage = (total_inserted / total_rows) * 100  # Calculate progress as percentage
                        print(f"Progress: {total_inserted}/{total_rows} rows inserted ({progress_percentage:.2f}% done) in {elapsed_time:.2f} seconds")
                    
                    # Execute stored procedure for each row
                    cursor.execute("""
                    EXEC sp_GenderPredictionMember @MyValueId = ?, @CustomerName = ?, @Predicted_Gender = ?
                    """,
                    row['MyValueId'],  # MyValueId
                    row['CustomerName'],  # Nama Customer
                    row['Predicted_Gender']  # Hasil Prediksi Gender
                    )
                    
                    total_inserted += 1
            
            
                except Exception as e:
                    print(f"Error inserting row {index}: {e}")
            
            # Final commit for any remaining data if total_inserted is not a multiple of 1000
            if total_inserted % commit_threshold != 0:
                conn.commit()
                print(f"Committed remaining {total_inserted % commit_threshold} rows to the database.")
            
            print(f"Total records inserted: {total_inserted}")

            cursor.close()
            conn.close()
            print("Data insertion process completed!")


        print("Data inserted successfully!")
        end_algorithm_time = time.time()
        elapsed_time = end_algorithm_time - start_algorithm_time
        minutes = int(elapsed_time // 60)  # Get whole minutes
        seconds = int(elapsed_time % 60)   # Get remaining seconds

        print(f"Algorithm estimated time completed: {minutes} minutes and {seconds} seconds")
        
    except Exception as e:
        print(f"An error occurred: {e}")

    print("Algorithm completed!")







import pyodbc
import pandas as pd

# Define the function to fetch and preprocess data
def preprocessing_dataset():
    print("Taking data from dataset...")
    try:
        GenderData = pd.read_csv("DatasetGenderNeededClarify.csv")
    except Exception as e:
        print(f"Failed to fetch data: {e}")
        return None
    finally:
        print("Data get!")

    # Drop null values in 'CustomerName'
    print("Cleaning data...")
    GenderData = GenderData.dropna(subset=['CustomerName'])
    print("Data successfully cleaned!")

    # Function to split names
    def split_name(name):
        name = name.lower()
        parts = name.split()
        
        first_name = second_name = third_name = fourth_name = last_name = ' '
        
        if len(parts) >= 1:
            first_name = parts[0]
        if len(parts) >= 2:
            second_name = parts[1]
        if len(parts) >= 3:
            third_name = parts[2]
        if len(parts) >= 4:
            fourth_name = parts[3]
        if len(parts) >= 5:
            last_name = ' '.join(parts[4:])
        
        return pd.Series([first_name, second_name, third_name, fourth_name, last_name])
    
    # Apply function to DataFrame
    print("Splitting customer names into individual parts...")
    GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']] = GenderData['CustomerName'].apply(split_name)
    print("Name splitting completed!")

    # Drop original 'CustomerName' and 'Gender' columns
    columns_to_drop = ['CustomerName', 'Gender']
    GenderData = GenderData.drop(columns=columns_to_drop, errors='ignore')
    
    print("Preprocessing completed successfully!")

    return GenderData


import time
import pandas as pd
import numpy as np
from datetime import datetime

def run_prediction():
    start_prediction_time = time.time()
    print("Starting the prediction process...")

    # Log execution time
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"Script executed at: {timestamp}")

    try:
        # Fetch and preprocess data
        print("Fetching and preprocessing dataset from csv...")
        GenderData = preprocessing_dataset()
        if GenderData is None or GenderData.empty:
            print("No data retrieved. Exiting process.")
            return
        print("Data fetched and preprocessed successfully!")

        def get_bigrams(name):
            return ' '.join(name[i:i+2] for i in range(len(name)-1)) if isinstance(name, str) else ""

        # Join all name columns into a single column
        X_new = GenderData[['FirstName', 'SecondName', 'ThirdName', 'FourthName', 'LastName']].astype(str)
        GenderData["CustomerName"] = X_new.apply(lambda row: ' '.join(row).strip(), axis=1)

        # Extract bigrams
        print("Extracting bigrams...")
        X_new = X_new.map(get_bigrams)
        X_new["FullName"] = X_new.apply(lambda row: ' '.join(row), axis=1)
        print("Bigrams extracted!")

        # Apply HashingVectorizer
        print("Applying feature transformation...")
        X_new_hashed = vectorizer.transform(X_new["FullName"])  
        X_new_df = pd.DataFrame(X_new_hashed.toarray())
        print("Feature transformation completed!")

        # Remove low-variance features
        print("Removing low-variance features...")
        X_new_df = pd.DataFrame(selector.transform(X_new_df))
        print("Low-variance features removed!")

        # Scale features
        print("Scaling features...")
        X_new_scaled = scaler.transform(X_new_df)
        print("Feature scaling completed!")

        # Predict using the trained model
        print("Model is predicting genders...")
        y_pred_new = rf.predict(X_new_scaled)
        print("Prediction completed!")

        # Map predictions back to 'M' and 'F'
        print("Mapping predictions to labels...")
        GenderData["Predicted_Gender"] = np.where(y_pred_new == 0, 'M', 'F')
        GenderData = GenderData[["MyValueId", "CustomerName", "Predicted_Gender"]]
        print("Mapping completed!")

        # Show preview of mapped data
        print("Preview of predicted data:")
        print(GenderData.head(10))  # Show first 10 rows
        
        # Save output
        output_filename = f"GenderData_Predicted_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        GenderData.head(100).to_csv(output_filename, index=False)
        print(f"Predicted data (first 100 rows) saved successfully as {output_filename}!")
        end_prediction_time = time.time()
        elapsed_time = end_prediction_time - start_prediction_time
        minutes = int(elapsed_time // 60)  # Get whole minutes
        seconds = int(elapsed_time % 60)   # Get remaining seconds

        print(f"Testing Time: {minutes} minutes and {seconds} seconds")

    except Exception as e:
        print(f"An error occurred: {e}")

    print("Prediction process completed!")






import time

while True:
    start_prediction_time = time.time()
    run_prediction()
    end_prediction_time = time.time()
    print(f"Testing Time: {end_prediction_time - start_prediction_time:.4f} seconds")
    
    # Sleep for 15 hour (900 seconds)
    
    print("Sleeping for 15 minutes...")
    time.sleep(300)


import time
import schedule

# Schedule the job to run at a specific time (e.g., 15:00 or 3:00 PM)
schedule.every().day.at("10:23").do(run_prediction)

while True:
    # Run any pending scheduled tasks
    schedule.run_pending()
    time.sleep(1)  # Small sleep to prevent a busy loop



import time
import schedule

schedule.clear()


# Schedule the job to run at 11:30 and 12:30 every day
schedule.every().day.at("13:10").do(run_prediction)

# Run the scheduled tasks
while True:
    schedule.run_pending()
    time.sleep(1)  # Small sleep to prevent a busy loop



schedule.clear()


run_prediction()



