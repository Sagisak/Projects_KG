{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75524fbe-335d-429f-bd88-0e19c36e160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SQL Server...\n",
      "Successfully connected to SQL Server!\n",
      "Processing query...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_21148\\4023732380.py:42: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  market = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched data from SQL Server!\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to fetch and preprocess data\n",
    "def preprocessing_dataset():\n",
    "    print(\"Connecting to SQL Server...\")\n",
    "    \n",
    "    try:\n",
    "        # Define connection string (replace with actual SQL Server details)\n",
    "        conn = pyodbc.connect(\n",
    "            \"DRIVER={SQL Server};\"\n",
    "            \"SERVER=10.12.30.240;\"\n",
    "            \"DATABASE=GORPDWHBI;\"  # Replace with your database name\n",
    "            \"UID=viewer;\"\n",
    "            \"PWD=viewer1;\"\n",
    "        )\n",
    "        print(\"Successfully connected to SQL Server!\")\n",
    "\n",
    "        # Query to fetch the required columns\n",
    "        query = \"\"\"\n",
    "SELECT\n",
    "b.TRANSACTIONID,\n",
    "c.DeptName\n",
    "FROM GORPDWH365.dbo.retailtransactionsalestrans a\n",
    "LEFT JOIN GORPDWH365.dbo.RETAILTRANSACTIONTABLE b ON a.TRANSACTIONID = b.TRANSACTIONID\n",
    "LEFT JOIN GORPDWHBI.dbo.DimProduct c on a.ITEMID = c.ItemID and a.DATAAREAID = c.DataAreaId\n",
    "LEFT JOIN GORPDWHBI.dbo.DimCustomer d on a.CUSTACCOUNT = d.CustomerId and a.DATAAREAID = d.DataAreaId\n",
    "LEFT JOIN GORPDWHBI.dbo.DimStore e on b.STORE = e.StoreId\n",
    "--WAJIB\n",
    "WHERE a.TRANSDATE BETWEEN '2024-01-01 00:00:00.000' AND '2024-12-31 00:00:00.000'\n",
    "  and b.TYPE IN (2,19)\n",
    "  and b.ENTRYSTATUS IN (0,2)\n",
    "  and a.TRANSACTIONSTATUS IN (0,2)\n",
    "  --WAJIB\n",
    "  and c.DivName LIKE '%DIV BOOKS%'\n",
    "  and c.DeptName IS NOT NULL\n",
    "  and e.StoreName LIKE '%MARGONDA%'\n",
    "        \"\"\"  # Ganti 'your_table_name' dengan nama tabel yang benar\n",
    "        print(\"Processing query...\")\n",
    "\n",
    "        # Fetch data into DataFrame\n",
    "        market = pd.read_sql(query, conn)\n",
    "        \n",
    "        # Close connection\n",
    "        conn.close()\n",
    "        print(\"Successfully fetched data from SQL Server!\")\n",
    "\n",
    "        return market  # Make sure 'market' is always returned\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect or fetch data: {e}\")\n",
    "        return None  # Return None if there's an error\n",
    "\n",
    "# Jalankan fungsi\n",
    "market = preprocessing_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ec6cbf-144f-4116-b6a8-58ec5c7d0826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TRANSACTIONID                     DeptName\n",
      "0        10150-10150-12-5653                   DEP NOVELS\n",
      "1        10150-10150-12-5653                   DEP NOVELS\n",
      "2        10150-10150-12-5653  DEP RELIGION & SPIRITUALITY\n",
      "3        10150-10150-12-5653                   DEP NOVELS\n",
      "4        10150-10150-12-5653                   DEP COMICS\n",
      "...                      ...                          ...\n",
      "234387  10150-10150-06-14216                DEP CLEARANCE\n",
      "234388  10150-10150-06-14114                DEP CLEARANCE\n",
      "234389  10150-10150-06-17839                DEP CLEARANCE\n",
      "234390  10150-10150-06-18253                DEP CLEARANCE\n",
      "234391  10150-10150-06-18325                DEP CLEARANCE\n",
      "\n",
      "[234392 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(market) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a8ed46-cd65-4180-b582-c5d16434f422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":white_check_mark: File 'Rekomendasi_Peletakan_Rak.xlsx' berhasil dibuat!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# :pushpin: 1. Konversi data transaksi per TRANSACTIONID\n",
    "transactions = market.groupby(\"TRANSACTIONID\")[\"DeptName\"].apply(list).tolist()\n",
    "\n",
    "# :pushpin: 2. One-hot encoding\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_).astype(bool)\n",
    "\n",
    "# :pushpin: 3. Jalankan FP-Growth untuk menemukan pola item yang sering muncul bersama\n",
    "frequent_itemsets = fpgrowth(df_encoded, min_support=0.00005, use_colnames=True, max_len=2)  # Atur min_support sesuai kebutuhan\n",
    "\n",
    "# :pushpin: 4. Generate aturan asosiasi dengan batas minimum confidence\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.00001)\n",
    "\n",
    "# :pushpin: 5. Menggabungkan aturan yang saling berlawanan (A → B & B → A)\n",
    "rekomendasi_rak = {}\n",
    "\n",
    "if not rules.empty:\n",
    "    for _, row in rules.iterrows():\n",
    "        lhs = list(row['antecedents'])[0]  # Left Hand Side (LHS)\n",
    "        rhs = list(row['consequents'])[0]  # Right Hand Side (RHS)\n",
    "        support = row['support']\n",
    "        confidence = row['confidence']\n",
    "        lift = row['lift']\n",
    "\n",
    "        # Buat pasangan unik (sorted agar A→B sama dengan B→A)\n",
    "        pair_key = tuple(sorted([lhs, rhs]))\n",
    "\n",
    "        # Simpan aturan dengan confidence tertinggi untuk setiap pasangan\n",
    "        if pair_key not in rekomendasi_rak or confidence > rekomendasi_rak[pair_key][2]:\n",
    "            rekomendasi_rak[pair_key] = (lhs, rhs, support, confidence, lift)\n",
    "\n",
    "    # Urutkan berdasarkan Lift tertinggi\n",
    "    sorted_rekomendasi = sorted(rekomendasi_rak.values(), key=lambda x: x[4], reverse=True)\n",
    "\n",
    "    # Buat DataFrame hasil\n",
    "    df_hasil = pd.DataFrame(sorted_rekomendasi, columns=[\"LHS\", \"RHS\", \"Support\", \"Confidence\", \"Lift\"])\n",
    "\n",
    "    # Simpan ke file Excel\n",
    "    df_hasil.to_excel(\"Rekomendasi_Peletakan_Rak.xlsx\", index=False)\n",
    "\n",
    "    print(\":white_check_mark: File 'Rekomendasi_Peletakan_Rak.xlsx' berhasil dibuat!\")\n",
    "else:\n",
    "    print(\":x: Tidak ada aturan yang ditemukan! Coba turunkan min_support atau min_threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f120d0a-a639-4666-893e-8e3c2393e87f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
